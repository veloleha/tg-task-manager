import redis.asyncio as redis
from redis.exceptions import RedisError
import json
from datetime import datetime
from config.settings import settings
import logging
from typing import Dict, List, Optional, Any

logger = logging.getLogger(__name__)

class RedisManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Redis"""
    def __init__(self):
        self.conn = None
        self.pubsub_conn = None  # –û—Ç–¥–µ–ª—å–Ω–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è PubSub
        self.task_counter = 0
        self._enhanced_stats = None  # Lazy initialization

    async def _ensure_connection(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis"""
        try:
            if self.conn is None:
                logger.info("Establishing Redis connection")
                self.conn = redis.Redis(
                    host=settings.REDIS_HOST,
                    port=settings.REDIS_PORT,
                    db=settings.REDIS_DB,
                    password=settings.REDIS_PASSWORD,
                    decode_responses=False,
                    socket_connect_timeout=5,
                    socket_timeout=5
                )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ PING
            if not await self.conn.ping():
                raise ConnectionError("Redis connection failed")
                
            # Initialize enhanced statistics if not already done
            if self._enhanced_stats is None:
                from .enhanced_statistics import EnhancedStatistics
                self._enhanced_stats = EnhancedStatistics(self)
                
        except Exception as e:
            logger.error(f"Redis connection error: {e}")
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            if self.conn:
                await self.conn.close()
            self.conn = None
            raise

    async def connect(self):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Redis"""
        logger.info("Calling Redis connect method")
        await self._ensure_connection()

    async def save_task(self, task_data: Dict[str, Any]) -> str:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∑–∞–¥–∞—á—É –≤ Redis —Å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é"""
        try:
            logger.info(f"[DB][SAVE_TASK] Starting task save operation...")
            await self._ensure_connection()
            logger.info(f"[DB][SAVE_TASK] Redis connection ensured")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –∑–∞–¥–∞—á–∏ –∏—Å–ø–æ–ª—å–∑—É—è UUID
            import uuid
            task_id = str(uuid.uuid4())
            full_key = f"task:{task_id}"
            logger.info(f"[DB][SAVE_TASK] Generated task ID: {task_id}, key: {full_key}")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            pipeline = self.conn.pipeline()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É JSON —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Å–ø–∏—Å–∫–æ–≤ –∏ –æ–±—ä–µ–∫—Ç–æ–≤
            def serialize_value(value):
                if value is None:
                    return ""
                elif isinstance(value, (list, dict)):
                    # –°–ø–∏—Å–∫–∏ –∏ —Å–ª–æ–≤–∞—Ä–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ JSON
                    return value
                else:
                    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
                    return str(value)
        
            task_json = json.dumps({
                k: serialize_value(v)
                for k, v in task_data.items()
            })
            logger.info(f"[DB][SAVE_TASK] Task data serialized to JSON: {len(task_json)} chars")
            
            pipeline.set(full_key, task_json)
            pipeline.expire(full_key, 604800)  # TTL 7 –¥–Ω–µ–π
            logger.info(f"[DB][SAVE_TASK] Added SET and EXPIRE commands to pipeline")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            pipeline.sadd("tasks:index", full_key)
            logger.info(f"[DB][SAVE_TASK] Added SADD command to pipeline for index")
            
            result = await pipeline.execute()
            logger.info(f"[DB][SAVE_TASK] Pipeline executed successfully: {result}")
            
            logger.info(f"[DB][SAVE_TASK] ‚úÖ Task saved with ID: {task_id} (key: {full_key})")
            return task_id  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ UUID, –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞
            
        except Exception as e:
            logger.error(f"[DB][SAVE_TASK] ‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏: {e}", exc_info=True)
            raise

    async def get_task(self, task_id: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–∞–¥–∞—á—É –ø–æ ID"""
        try:
            logger.info(f"[DB][GET_TASK] Starting task retrieval for ID: {task_id}")
            await self._ensure_connection()
            logger.info(f"[DB][GET_TASK] Redis connection ensured")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
            if not task_id.startswith("task:"):
                full_key = f"task:{task_id}"
            else:
                full_key = task_id
            logger.info(f"[DB][GET_TASK] Using key: {full_key}")
            
            task_json = await self.conn.get(full_key)
            logger.info(f"[DB][GET_TASK] Redis GET result: {task_json is not None} (length: {len(task_json) if task_json else 0})")
            
            if not task_json:
                logger.warning(f"[DB][GET_TASK] ‚ö†Ô∏è Task not found: {task_id} (key: {full_key})")
                return {}
                
            if isinstance(task_json, bytes):
                task_json = task_json.decode('utf-8')
                logger.info(f"[DB][GET_TASK] Decoded bytes to string")
                
            task_data = json.loads(task_json)
            logger.info(f"[DB][GET_TASK] ‚úÖ Task retrieved successfully: {task_id} (key: {full_key}) - {len(task_data)} fields")
            return task_data
            
        except Exception as e:
            logger.error(f"[DB][GET_TASK] ‚ùå Error getting task {task_id}: {e}", exc_info=True)
            return {}

    async def update_task(self, task_id: str, **fields):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø–æ–ª—è –∑–∞–¥–∞—á–∏"""
        try:
            await self._ensure_connection()
            task = await self.get_task(task_id)
            if not task:
                return False
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
            if not task_id.startswith("task:"):
                full_key = f"task:{task_id}"
            else:
                full_key = task_id
                
            task.update(fields)
            await self.conn.set(full_key, json.dumps(task))
            logger.debug(f"Task updated: {task_id} (key: {full_key})")
            return True
        except Exception as e:
            logger.error(f"Error updating task {task_id}: {e}")
            return False

    async def update_task_status(self, task_id: str, status: str, executor: str = None) -> bool:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º —Å—á—ë—Ç—á–∏–∫–æ–≤"""
        try:
            await self._ensure_connection()
            
            # Ensure enhanced stats is initialized
            if self._enhanced_stats is None:
                from .enhanced_statistics import EnhancedStatistics
                self._enhanced_stats = EnhancedStatistics(self)
            
            task = await self.get_task(task_id)
            if not task:
                return False
            
            old_status = task.get('status')
            old_executor = task.get('assignee')
            
            # Update task data
            task['status'] = status
            if executor:
                task['assignee'] = executor
            task['updated_at'] = datetime.utcnow().isoformat()
            
            await self.conn.set(f"task:{task_id}", json.dumps(task))
            
            # Update statistics counters
            current_executor = executor or old_executor
            await self._enhanced_stats.update_task_status_counters(
                old_status, status, current_executor
            )
            
            logger.debug(f"Task status updated: {task_id} -> {status} (executor: {current_executor})")
            return True
        except Exception as e:
            logger.error(f"Error updating task status: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return False

    async def set_assignee(self, task_id: str, username: str):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è –∑–∞–¥–∞—á–∏"""
        try:
            await self._ensure_connection()
            task = await self.get_task(task_id)
            if not task:
                return False
                
            task['assignee'] = username
            await self.conn.set(f"task:{task_id}", json.dumps(task))
            return True
        except Exception as e:
            logger.error(f"Error setting assignee: {e}")
            raise

    async def get_tasks_by_status(self, status: str) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –∑–∞–¥–∞—á–∏ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º —Å—Ç–∞—Ç—É—Å–æ–º"""
        try:
            await self._ensure_connection()
            tasks = []
            async for key in self.conn.scan_iter("task:*"):
                task = await self.get_task(key)
                if task.get("status") == status:
                    tasks.append(task)
            return tasks
        except Exception as e:
            logger.error(f"Error getting tasks by status: {e}")
            return []

    async def get_tasks_by_assignee(self, assignee: str) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –∑–∞–¥–∞—á–∏ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–º"""
        try:
            await self._ensure_connection()
            tasks = []
            async for key in self.conn.scan_iter("task:*"):
                task = await self.get_task(key)
                if task.get("assignee") == assignee:
                    tasks.append(task)
            return tasks
        except Exception as e:
            logger.error(f"Error getting tasks by assignee: {e}")
            return []

    async def get_global_stats(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∑–∞–¥–∞—á–∞–º"""
        try:
            await self._ensure_connection()
            
            # Ensure enhanced stats is initialized
            if self._enhanced_stats is None:
                from .enhanced_statistics import EnhancedStatistics
                self._enhanced_stats = EnhancedStatistics(self)
                
            return await self._enhanced_stats.get_global_stats()
        except Exception as e:
            logger.error(f"Error getting global stats: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return {
                "unreacted": 0,
                "in_progress": 0,
                "completed": 0,
                "executors": {}
            }

    async def get_executors_stats(self) -> Dict[str, Dict[str, int]]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è–º"""
        try:
            await self._ensure_connection()
            executors = set()
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ—Ö –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π
            async for key in self.conn.scan_iter("task:*"):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º task_id –∏–∑ –∫–ª—é—á–∞
                if isinstance(key, bytes):
                    key = key.decode('utf-8')
                task_id = key.split(':', 1)[1] if ':' in key else key
                task = await self.get_task(task_id)
                if assignee := task.get("assignee"):
                    executors.add(assignee)
            
            # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats = {}
            for executor in executors:
                stats[executor] = {
                    "in_progress": int(await self.conn.get(f"stats:in_progress:{executor}") or 0),
                    "completed": int(await self.conn.get(f"stats:completed:{executor}") or 0)
                }
            
            return stats
        except Exception as e:
            logger.error(f"Error getting executors stats: {e}")
            return {}

    async def increment_counter(self, counter_type: str):
        """–£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Å—á–µ—Ç—á–∏–∫ –∑–∞–¥–∞—á"""
        try:
            await self._ensure_connection()
            await self.conn.incr(f"counter:{counter_type}")
        except Exception as e:
            logger.error(f"Error incrementing counter: {e}")
            raise

    async def publish_event(self, channel: str, data: Dict[str, Any]):
        """–ü—É–±–ª–∏–∫—É–µ—Ç —Å–æ–±—ã—Ç–∏–µ –≤ Redis Pub/Sub"""
        try:
            await self._ensure_connection()
            await self.conn.publish(channel, json.dumps(data))
            logger.info(f"[USERBOT][STEP 2] Published event to {channel}: {data}")
        except Exception as e:
            logger.error(f"Error publishing event: {e}")
            raise

    async def get_pubsub(self, fresh: bool = False):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç Pub/Sub —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ–º"""
        try:
            if fresh or self.pubsub_conn is None:
                # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å—Ç–∞—Ä–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –µ—Å–ª–∏ –±—ã–ª–æ
                if self.pubsub_conn:
                    await self.pubsub_conn.close()
                
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è PubSub
                self.pubsub_conn = redis.Redis(
                    host=settings.REDIS_HOST,
                    port=settings.REDIS_PORT,
                    db=settings.REDIS_DB,
                    password=settings.REDIS_PASSWORD,
                    socket_connect_timeout=5,
                    socket_timeout=30,  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è PubSub
                    max_connections=10,
                    health_check_interval=30
                )
            
            return self.pubsub_conn.pubsub()
        except Exception as e:
            logger.error(f"PubSub connection error: {e}")
            raise

    async def is_connected(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis"""
        try:
            if self.conn is None:
                return False
            return await self.conn.ping()
        except (RedisError, Exception):
            return False

    async def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Redis"""
        if self.conn:
            await self.conn.close()
            self.conn = None
    
    async def get_next_task_number(self) -> int:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –∑–∞–¥–∞—á–∏"""
        return await self.conn.incr("global_task_counter")

    async def get_task(self, task_id: str) -> Optional[dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–∞–¥–∞—á—É –ø–æ ID"""
        task_data = await self.conn.get(f"task:{task_id}")
        if task_data:
            return json.loads(task_data)
        return None
    
    async def update_task_data(self, task_id: str, task_data: dict):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∑–∞–¥–∞—á—É"""
        await self.conn.set(f"task:{task_id}", json.dumps(task_data))

    async def get(self, key: str) -> Optional[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –∫–ª—é—á—É"""
        if self.conn is None:
            await self._ensure_connection()
        return await self.conn.get(key)
    
    async def set(self, key: str, value: str):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –∫–ª—é—á—É"""
        if self.conn is None:
            await self._ensure_connection()
        await self.conn.set(key, value)
    
    async def set_pinned_message_id(self, message_id: int):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç ID –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        await self._ensure_connection()
        await self.conn.set("pinned_stats_message_id", str(message_id))
        logger.info(f"Saved pinned message ID: {message_id}")
    
    async def get_pinned_message_id(self) -> Optional[int]:
        """–ü–æ–ª—É—á–∞–µ—Ç ID –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        await self._ensure_connection()
        message_id = await self.conn.get("pinned_stats_message_id")
        if message_id:
            return int(message_id.decode() if isinstance(message_id, bytes) else message_id)
        return None
    
    async def clear_pinned_message_id(self):
        """–£–¥–∞–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π ID –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        await self._ensure_connection()
        await self.conn.delete("pinned_stats_message_id")
        logger.info("Cleared pinned message ID")
    
    async def delete_task(self, task_id: str):
        """–£–¥–∞–ª—è–µ—Ç –∑–∞–¥–∞—á—É –∏–∑ Redis"""
        try:
            await self._ensure_connection()
            
            # –£–¥–∞–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∑–∞–ø–∏—Å—å –∑–∞–¥–∞—á–∏
            task_key = f"task:{task_id}"
            pipeline = self.conn.pipeline()
            
            # –£–¥–∞–ª—è–µ–º –∑–∞–¥–∞—á—É
            pipeline.delete(task_key)
            
            # –£–¥–∞–ª—è–µ–º –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
            pipeline.srem("tasks:index", task_key)
            
            result = await pipeline.execute()
            logger.info(f"Task {task_id} deleted from Redis: {result}")
            
        except Exception as e:
            logger.error(f"Error deleting task {task_id}: {e}")
            raise
    
    # ==================== ENHANCED STATISTICS METHODS ====================
    
    async def get_period_stats(self, period: str) -> Dict[str, Dict[str, int]]:
        """Get statistics for a specific period (day/week/month)"""
        try:
            await self._ensure_connection()
            
            # Ensure enhanced stats is initialized
            if self._enhanced_stats is None:
                from .enhanced_statistics import EnhancedStatistics
                self._enhanced_stats = EnhancedStatistics(self)
                
            return await self._enhanced_stats.get_period_stats(period)
        except Exception as e:
            logger.error(f"Error getting {period} stats: {e}")
            return {}
    
    async def format_pinned_message(self, stats: Dict[str, Any] = None) -> str:
        """Format enhanced pinned message with executor statistics"""
        try:
            await self._ensure_connection()
            
            # Ensure enhanced stats is initialized
            if self._enhanced_stats is None:
                from .enhanced_statistics import EnhancedStatistics
                self._enhanced_stats = EnhancedStatistics(self)
            
            if stats is None:
                stats = await self.get_global_stats()
            return self._enhanced_stats.format_pinned_message(stats)
        except Exception as e:
            logger.error(f"Error formatting pinned message: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return "üìä –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"
    
    async def format_period_stats_message(self, period: str, stats: Dict[str, Dict[str, int]] = None) -> str:
        """Format period statistics message"""
        try:
            await self._ensure_connection()
            
            # Ensure enhanced stats is initialized
            if self._enhanced_stats is None:
                from .enhanced_statistics import EnhancedStatistics
                self._enhanced_stats = EnhancedStatistics(self)
                
            if stats is None:
                stats = await self.get_period_stats(period)
            return self._enhanced_stats.format_period_stats_message(period, stats)
        except Exception as e:
            logger.error(f"Error formatting period stats: {e}")
            return f"üìà –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ {period}"
    
    async def reset_all_counters(self):
        """Reset all statistics counters (for testing/debugging)"""
        try:
            await self._ensure_connection()
            
            # Ensure enhanced stats is initialized
            if self._enhanced_stats is None:
                from .enhanced_statistics import EnhancedStatistics
                self._enhanced_stats = EnhancedStatistics(self)
                
            await self._enhanced_stats.reset_all_counters()
        except Exception as e:
            logger.error(f"Error resetting counters: {e}")
            raise


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∏–µ–Ω—Ç–∞ Redis
redis_client = RedisManager()
