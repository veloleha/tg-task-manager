import redis.asyncio as redis
from redis.exceptions import RedisError
import json
from datetime import datetime
from config.settings import settings
import logging
from typing import Dict, List, Optional, Any

logger = logging.getLogger(__name__)

class RedisManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Redis"""
    def __init__(self):
        self.conn = None
        self.pubsub_conn = None  # –û—Ç–¥–µ–ª—å–Ω–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è PubSub
        self.task_counter = 0
        self._enhanced_stats = None  # Lazy initialization

    async def _ensure_connection(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis"""
        try:
            if self.conn is None:
                logger.info("Establishing Redis connection")
                self.conn = redis.Redis(
                    host=settings.REDIS_HOST,
                    port=settings.REDIS_PORT,
                    db=settings.REDIS_DB,
                    password=settings.REDIS_PASSWORD,
                    decode_responses=False,
                    socket_connect_timeout=5,
                    socket_timeout=5
                )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ PING
            if not await self.conn.ping():
                raise ConnectionError("Redis connection failed")
                
            # Initialize enhanced statistics if not already done
            if self._enhanced_stats is None:
                from .enhanced_statistics import EnhancedStatistics
                self._enhanced_stats = EnhancedStatistics(self)
                
        except Exception as e:
            logger.error(f"Redis connection error: {e}")
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            if self.conn:
                await self.conn.close()
            self.conn = None
            raise

    async def connect(self):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Redis"""
        logger.info("Calling Redis connect method")
        await self._ensure_connection()

    async def save_task(self, task_data: Dict[str, Any]) -> str:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∑–∞–¥–∞—á—É –≤ Redis —Å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é"""
        try:
            logger.info(f"[DB][SAVE_TASK] Starting task save operation...")
            await self._ensure_connection()
            logger.info(f"[DB][SAVE_TASK] Redis connection ensured")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –∑–∞–¥–∞—á–∏ –∏—Å–ø–æ–ª—å–∑—É—è UUID
            import uuid
            task_id = str(uuid.uuid4())
            full_key = f"task:{task_id}"
            logger.info(f"[DB][SAVE_TASK] Generated task ID: {task_id}, key: {full_key}")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            pipeline = self.conn.pipeline()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫—É JSON —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Å–ø–∏—Å–∫–æ–≤ –∏ –æ–±—ä–µ–∫—Ç–æ–≤
            def serialize_value(value):
                if value is None:
                    return ""
                elif isinstance(value, (list, dict)):
                    # –°–ø–∏—Å–∫–∏ –∏ —Å–ª–æ–≤–∞—Ä–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ JSON
                    return value
                else:
                    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
                    return str(value)
        
            task_json = json.dumps({
                k: serialize_value(v)
                for k, v in task_data.items()
            })
            logger.info(f"[DB][SAVE_TASK] Task data serialized to JSON: {len(task_json)} chars")
            
            pipeline.set(full_key, task_json)
            pipeline.expire(full_key, 604800)  # TTL 7 –¥–Ω–µ–π
            logger.info(f"[DB][SAVE_TASK] Added SET and EXPIRE commands to pipeline")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            pipeline.sadd("tasks:index", full_key)
            logger.info(f"[DB][SAVE_TASK] Added SADD command to pipeline for index")
            
            result = await pipeline.execute()
            logger.info(f"[DB][SAVE_TASK] Pipeline executed successfully: {result}")
            
            logger.info(f"[DB][SAVE_TASK] ‚úÖ Task saved with ID: {task_id} (key: {full_key})")
            return task_id  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ UUID, –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞
            
        except Exception as e:
            logger.error(f"[DB][SAVE_TASK] ‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏: {e}", exc_info=True)
            raise

    async def get_task(self, task_id: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–∞–¥–∞—á—É –ø–æ ID"""
        try:
            logger.info(f"[DB][GET_TASK] Starting task retrieval for ID: {task_id}")
            await self._ensure_connection()
            logger.info(f"[DB][GET_TASK] Redis connection ensured")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
            if not task_id.startswith("task:"):
                full_key = f"task:{task_id}"
            else:
                full_key = task_id
            logger.info(f"[DB][GET_TASK] Using key: {full_key}")
            
            task_json = await self.conn.get(full_key)
            logger.info(f"[DB][GET_TASK] Redis GET result: {task_json is not None} (length: {len(task_json) if task_json else 0})")
            
            if not task_json:
                logger.warning(f"[DB][GET_TASK] ‚ö†Ô∏è Task not found: {task_id} (key: {full_key})")
                return {}
                
            if isinstance(task_json, bytes):
                task_json = task_json.decode('utf-8')
                logger.info(f"[DB][GET_TASK] Decoded bytes to string")
                
            task_data = json.loads(task_json)
            logger.info(f"[DB][GET_TASK] ‚úÖ Task retrieved successfully: {task_id} (key: {full_key}) - {len(task_data)} fields")
            return task_data
            
        except Exception as e:
            logger.error(f"[DB][GET_TASK] ‚ùå Error getting task {task_id}: {e}", exc_info=True)
            return {}

    async def update_task(self, task_id: str, **fields):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø–æ–ª—è –∑–∞–¥–∞—á–∏"""
        try:
            await self._ensure_connection()
            task = await self.get_task(task_id)
            if not task:
                return False
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
            if not task_id.startswith("task:"):
                full_key = f"task:{task_id}"
            else:
                full_key = task_id
                
            task.update(fields)
            await self.conn.set(full_key, json.dumps(task))
            logger.debug(f"Task updated: {task_id} (key: {full_key})")
            return True
        except Exception as e:
            logger.error(f"Error updating task {task_id}: {e}")
            return False

    async def update_task_status(self, task_id: str, status: str, executor: str = None) -> bool:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ —Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º —Å—á—ë—Ç—á–∏–∫–æ–≤"""
        try:
            await self._ensure_connection()
            
            # Ensure enhanced stats is initialized
            if self._enhanced_stats is None:
                from .enhanced_statistics import EnhancedStatistics
                self._enhanced_stats = EnhancedStatistics(self)
            
            task = await self.get_task(task_id)
            if not task:
                return False
            
            old_status = task.get('status')
            old_executor = task.get('assignee')
            
            # Update task data
            task['status'] = status
            if executor:
                task['assignee'] = executor
            task['updated_at'] = datetime.utcnow().isoformat()
            
            await self.conn.set(f"task:{task_id}", json.dumps(task))
            
            # Update statistics counters
            current_executor = executor or old_executor
            await self._enhanced_stats.update_task_status_counters(
                old_status, status, current_executor
            )
            
            logger.debug(f"Task status updated: {task_id} -> {status} (executor: {current_executor})")
            return True
        except Exception as e:
            logger.error(f"Error updating task status: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return False

    async def set_assignee(self, task_id: str, username: str):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è –∑–∞–¥–∞—á–∏"""
        try:
            await self._ensure_connection()
            task = await self.get_task(task_id)
            if not task:
                return False
                
            task['assignee'] = username
            await self.conn.set(f"task:{task_id}", json.dumps(task))
            return True
        except Exception as e:
            logger.error(f"Error setting assignee: {e}")
            raise

    async def get_tasks_by_status(self, status: str) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –∑–∞–¥–∞—á–∏ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º —Å—Ç–∞—Ç—É—Å–æ–º"""
        try:
            await self._ensure_connection()
            tasks = []
            async for key in self.conn.scan_iter("task:*"):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º task_id –∏–∑ –∫–ª—é—á–∞ (—É–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å "task:")
                task_id = key.decode('utf-8').replace('task:', '')
                task = await self.get_task(task_id)
                if task and task.get("status") == status:
                    # –î–æ–±–∞–≤–ª—è–µ–º task_id –≤ –¥–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
                    task['task_id'] = task_id
                    tasks.append(task)
            return tasks
        except Exception as e:
            logger.error(f"Error getting tasks by status: {e}")
            return []

    async def get_tasks_by_assignee(self, assignee: str) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –∑–∞–¥–∞—á–∏ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–º"""
        try:
            await self._ensure_connection()
            keys = await self.conn.smembers("tasks:index")
            tasks = []
            for key in keys:
                task_id = key.decode().split(":")[1]
                task_data = await self.get_task(task_id)
                if task_data and task_data.get("assignee") == assignee:
                    task_data['task_id'] = task_id  # Add missing field
                    tasks.append(task_data)
            return tasks
        except Exception as e:
            logger.error(f"Error getting tasks by assignee {assignee}: {e}")
            return []
    
    async def get_user_tasks(self, user_id: int) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            await self._ensure_connection()
            keys = await self.conn.smembers("tasks:index")
            tasks = []
            deleted_keys = []  # –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–π —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∏–Ω–¥–µ–∫—Å–∞
            
            for key in keys:
                task_id = key.decode().split(":")[1]
                logger.info(f"[DB][GET_USER_TASKS] Checking task {task_id} for user {user_id}")
                task_data = await self.get_task(task_id)
                logger.info(f"[DB][GET_USER_TASKS] Task {task_id} data: {task_data}")
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: get_task –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç {} –¥–ª—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–¥–∞—á, –∞ –Ω–µ None
                task_exists = task_data and len(task_data) > 0 and 'user_id' in task_data and 'status' in task_data
                logger.info(f"[DB][GET_USER_TASKS] Task {task_id} exists: {task_exists}")
            
                if task_exists and str(task_data.get("user_id")) == str(user_id):
                    logger.info(f"[DB][GET_USER_TASKS] Task {task_id} belongs to user {user_id}")
                    task_data['task_id'] = task_id  # Add missing field
                    tasks.append(task_data)
                elif not task_exists:
                    logger.info(f"[DB][GET_USER_TASKS] Task {task_id} marked for cleanup (deleted)")
                    # –ó–∞–¥–∞—á–∞ —É–¥–∞–ª–µ–Ω–∞, –Ω–æ –∫–ª—é—á –æ—Å—Ç–∞–ª—Å—è –≤ –∏–Ω–¥–µ–∫—Å–µ - –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
                    deleted_keys.append(key)
            
            # –û—á–∏—â–∞–µ–º –∏–Ω–¥–µ–∫—Å –æ—Ç —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
            if deleted_keys:
                logger.info(f"Cleaning up {len(deleted_keys)} deleted task keys from index")
                pipeline = self.conn.pipeline()
                for deleted_key in deleted_keys:
                    pipeline.srem("tasks:index", deleted_key)
                await pipeline.execute()
                logger.info(f"Successfully cleaned up {len(deleted_keys)} deleted task keys from index")
                
            return tasks
        except Exception as e:
            logger.error(f"Error getting tasks for user {user_id}: {e}")
            return []

    async def get_executors_stats(self) -> Dict[str, Dict[str, int]]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è–º"""
        try:
            await self._ensure_connection()
            executors = set()
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ—Ö –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π
            async for key in self.conn.scan_iter("task:*"):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º task_id –∏–∑ –∫–ª—é—á–∞
                if isinstance(key, bytes):
                    key = key.decode('utf-8')
                task_id = key.split(':', 1)[1] if ':' in key else key
                task = await self.get_task(task_id)
                if assignee := task.get("assignee"):
                    executors.add(assignee)
            
            # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats = {}
            for executor in executors:
                stats[executor] = {
                    "in_progress": int(await self.conn.get(f"stats:in_progress:{executor}") or 0),
                    "completed": int(await self.conn.get(f"stats:completed:{executor}") or 0)
                }
            
            return stats
        except Exception as e:
            logger.error(f"Error getting executors stats: {e}")
            return {}

    async def increment_counter(self, counter_type: str):
        """–£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Å—á–µ—Ç—á–∏–∫ –∑–∞–¥–∞—á"""
        try:
            await self._ensure_connection()
            await self.conn.incr(f"stats:{counter_type}")
        except Exception as e:
            logger.error(f"Error incrementing counter {counter_type}: {e}")

    async def publish_event(self, channel: str, data: Dict[str, Any]):
        """–ü—É–±–ª–∏–∫—É–µ—Ç —Å–æ–±—ã—Ç–∏–µ –≤ Redis Pub/Sub"""
        try:
            await self._ensure_connection()
            await self.conn.publish(channel, json.dumps(data))
            logger.info(f"[USERBOT][STEP 2] Published event to {channel}: {data}")
        except Exception as e:
            logger.error(f"Error publishing event: {e}")
            raise

    async def get_pubsub(self, fresh: bool = False):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç Pub/Sub —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ–º"""
        try:
            if fresh or self.pubsub_conn is None:
                # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å—Ç–∞—Ä–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –µ—Å–ª–∏ –±—ã–ª–æ
                if self.pubsub_conn:
                    await self.pubsub_conn.close()
                
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è PubSub
                self.pubsub_conn = redis.Redis(
                    host=settings.REDIS_HOST,
                    port=settings.REDIS_PORT,
                    db=settings.REDIS_DB,
                    password=settings.REDIS_PASSWORD,
                    socket_connect_timeout=5,
                    socket_timeout=30,  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è PubSub
                    max_connections=10,
                    health_check_interval=30
                )
            
            return self.pubsub_conn.pubsub()
        except Exception as e:
            logger.error(f"PubSub connection error: {e}")
            raise

    async def is_connected(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis"""
        try:
            if self.conn is None:
                return False
            return await self.conn.ping()
        except (RedisError, Exception):
            return False

    async def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Redis"""
        if self.conn:
            await self.conn.close()
            self.conn = None
    
    async def get_next_task_number(self) -> int:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –∑–∞–¥–∞—á–∏"""
        return await self.conn.incr("global_task_counter")

    async def get_task(self, task_id: str) -> Optional[dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–∞–¥–∞—á—É –ø–æ ID"""
        logger.info(f"[DB][GET_TASK] Attempting to get task {task_id}")
        task_data = await self.conn.get(f"task:{task_id}")
        logger.info(f"[DB][GET_TASK] Raw data for task {task_id}: {task_data}")
        if task_data:
            result = json.loads(task_data)
            logger.info(f"[DB][GET_TASK] Parsed task {task_id} data: {result}")
            return result
        logger.info(f"[DB][GET_TASK] Task {task_id} not found, returning None")
        return None
    
    async def update_task_data(self, task_id: str, task_data: dict):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∑–∞–¥–∞—á—É"""
        await self.conn.set(f"task:{task_id}", json.dumps(task_data))

    async def get(self, key: str) -> Optional[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –∫–ª—é—á—É"""
        if self.conn is None:
            await self._ensure_connection()
        return await self.conn.get(key)
    
    async def set(self, key: str, value: str):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –∫–ª—é—á—É"""
        if self.conn is None:
            await self._ensure_connection()
        await self.conn.set(key, value)
    
    async def set_pinned_message_id(self, message_id: Optional[int]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç ID –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        await self._ensure_connection()
        if message_id is None:
            await self.conn.delete("pinned_stats_message_id")
            logger.info("Cleared pinned message ID")
        else:
            await self.conn.set("pinned_stats_message_id", str(message_id))
            logger.info(f"Saved pinned message ID: {message_id}")
    
    async def get_pinned_message_id(self) -> Optional[int]:
        """–ü–æ–ª—É—á–∞–µ—Ç ID –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        await self._ensure_connection()
        message_id = await self.conn.get("pinned_stats_message_id")
        if message_id:
            try:
                message_id_str = message_id.decode() if isinstance(message_id, bytes) else message_id
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ —Å—Ç—Ä–æ–∫–∞ 'None'
                if message_id_str == 'None' or message_id_str == 'null':
                    logger.warning(f"Found invalid pinned message ID: {message_id_str}, clearing it")
                    await self.conn.delete("pinned_stats_message_id")
                    return None
                return int(message_id_str)
            except (ValueError, TypeError) as e:
                logger.error(f"Invalid pinned message ID format: {message_id}, error: {e}")
                # –û—á–∏—â–∞–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                await self.conn.delete("pinned_stats_message_id")
                return None
        return None
    
    async def clear_pinned_message_id(self):
        """–£–¥–∞–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π ID –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        await self._ensure_connection()
        await self.conn.delete("pinned_stats_message_id")
        logger.info("Cleared pinned message ID")
    
    async def delete_task(self, task_id: str):
        """–£–¥–∞–ª—è–µ—Ç –∑–∞–¥–∞—á—É –∏–∑ Redis"""
        try:
            await self._ensure_connection()
            
            # –£–¥–∞–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∑–∞–ø–∏—Å—å –∑–∞–¥–∞—á–∏
            task_key = f"task:{task_id}"
            logger.info(f"[DB][DELETE_TASK] Attempting to delete task {task_id} with key {task_key}")
            
            # –ü–æ–ª—É—á–∞–µ–º –∑–∞–¥–∞—á—É –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è user_id
            task_data = await self.get_task(task_id)
            user_id = task_data.get('user_id') if task_data else None
            logger.info(f"[DB][DELETE_TASK] Task user_id: {user_id}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∑–∞–¥–∞—á–∞ –¥–æ —É–¥–∞–ª–µ–Ω–∏—è
            task_exists_before = await self.conn.exists(task_key)
            logger.info(f"[DB][DELETE_TASK] Task {task_id} exists before deletion: {task_exists_before}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —É–¥–∞–ª—è–µ–º –∑–∞–¥–∞—á—É –∏–∑ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤
            pipeline = self.conn.pipeline()
            
            # –£–¥–∞–ª—è–µ–º –∑–∞–¥–∞—á—É
            pipeline.delete(task_key)
            
            # –£–¥–∞–ª—è–µ–º –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
            pipeline.srem("tasks:index", task_key)
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å user_id, —É–¥–∞–ª—è–µ–º –∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ (–µ—Å–ª–∏ —Ç–∞–∫–æ–π —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
            if user_id:
                user_index_key = f"user_tasks:{user_id}"
                pipeline.srem(user_index_key, task_key)
                logger.info(f"[DB][DELETE_TASK] Added removal from user index {user_index_key}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞: —É–¥–∞–ª—è–µ–º –∏–∑ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∏–Ω–¥–µ–∫—Å–æ–≤
            # –≠—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —É—Ç–µ—á–µ–∫ –≤ —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ user_id –∏–∑–º–µ–Ω–∏–ª—Å—è
            all_user_keys = await self.conn.keys("user_tasks:*")
            for user_key in all_user_keys:
                pipeline.srem(user_key, task_key)
            
            result = await pipeline.execute()
            logger.info(f"[DB][DELETE_TASK] Task {task_id} deletion result: {result}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∑–∞–¥–∞—á–∞ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è
            task_exists_after = await self.conn.exists(task_key)
            logger.info(f"[DB][DELETE_TASK] Task {task_id} exists after deletion: {task_exists_after}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–∞–¥–∞—á–∞ –≤ –∏–Ω–¥–µ–∫—Å–µ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è
            in_index_after = await self.conn.sismember("tasks:index", task_key)
            logger.info(f"[DB][DELETE_TASK] Task {task_id} in index after deletion: {in_index_after}")
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∑–∞–¥–∞—á–∞ —É–¥–∞–ª–µ–Ω–∞ –∏–∑ –≤—Å–µ—Ö –∏–Ω–¥–µ–∫—Å–æ–≤
            if task_exists_after:
                logger.warning(f"[DB][DELETE_TASK] Task {task_id} still exists after deletion, forcing additional cleanup")
                await self.conn.delete(task_key)
                
            if in_index_after:
                logger.warning(f"[DB][DELETE_TASK] Task {task_id} still in index after deletion, forcing additional cleanup")
                await self.conn.srem("tasks:index", task_key)
                
        except Exception as e:
            logger.error(f"[DB][DELETE_TASK] Error deleting task {task_id}: {e}")
            import traceback
            logger.error(f"[DB][DELETE_TASK] Traceback: {traceback.format_exc()}")
            raise
    
    # ==================== ENHANCED STATISTICS METHODS ====================
    
    async def get_period_stats(self, period: str) -> Dict[str, Dict[str, int]]:
        """Get statistics for a specific period (day/week/month)"""
        try:
            await self._ensure_connection()
            
            # Ensure enhanced stats is initialized
            if self._enhanced_stats is None:
                from .enhanced_statistics import EnhancedStatistics
                self._enhanced_stats = EnhancedStatistics(self)
                
            return await self._enhanced_stats.get_period_stats(period)
        except Exception as e:
            logger.error(f"Error getting {period} stats: {e}")
            return {}
    
    async def format_pinned_message(self, stats: Dict[str, Any] = None) -> str:
        """Format enhanced pinned message with executor statistics"""
        try:
            await self._ensure_connection()
            
            # Ensure enhanced stats is initialized
            if self._enhanced_stats is None:
                from .enhanced_statistics import EnhancedStatistics
                self._enhanced_stats = EnhancedStatistics(self)
            
            if stats is None:
                stats = await self._enhanced_stats.get_global_stats()
            return self._enhanced_stats.format_pinned_message(stats)
        except Exception as e:
            logger.error(f"Error formatting pinned message: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return "üìä –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"
    
    async def format_period_stats_message(self, period: str, stats: Dict[str, Dict[str, int]] = None) -> str:
        """Format period statistics message"""
        try:
            await self._ensure_connection()
            
            # Ensure enhanced stats is initialized
            if self._enhanced_stats is None:
                from .enhanced_statistics import EnhancedStatistics
                self._enhanced_stats = EnhancedStatistics(self)
                
            if stats is None:
                stats = await self.get_period_stats(period)
            return self._enhanced_stats.format_period_stats_message(period, stats)
        except Exception as e:
            logger.error(f"Error formatting period stats: {e}")
            return f"üìà –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ {period}"
    
    async def get_global_stats(self) -> Dict[str, Any]:
        """Get comprehensive global statistics"""
        try:
            await self._ensure_connection()
            
            # Ensure enhanced stats is initialized
            if self._enhanced_stats is None:
                from .enhanced_statistics import EnhancedStatistics
                self._enhanced_stats = EnhancedStatistics(self)
                
            return await self._enhanced_stats.get_global_stats()
        except Exception as e:
            logger.error(f"Error getting global stats: {e}")
            return {
                "unreacted": 0,
                "in_progress": 0,
                "completed": 0,
                "executors": {}
            }
    
    async def reset_all_counters(self):
        """Reset all statistics counters (for testing/debugging)"""
        try:
            await self._ensure_connection()
            
            # Ensure enhanced stats is initialized
            if self._enhanced_stats is None:
                from .enhanced_statistics import EnhancedStatistics
                self._enhanced_stats = EnhancedStatistics(self)
                
            await self._enhanced_stats.reset_all_counters()
        except Exception as e:
            logger.error(f"Error resetting counters: {e}")
            raise


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∏–µ–Ω—Ç–∞ Redis
redis_client = RedisManager()
